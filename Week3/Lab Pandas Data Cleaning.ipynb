{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Cleaning</a></span></li><li><span><a href=\"#Examining-Data-for-Potential-Issues\" data-toc-modified-id=\"Examining-Data-for-Potential-Issues-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Examining Data for Potential Issues</a></span></li><li><span><a href=\"#Missing-Values\" data-toc-modified-id=\"Missing-Values-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Missing Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Show-the-number-of-null-values-only-of-the-columns-that-actually-have-null-values\" data-toc-modified-id=\"Show-the-number-of-null-values-only-of-the-columns-that-actually-have-null-values-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Show the number of null values only of the columns that actually have null values</a></span></li><li><span><a href=\"#Remove-the-columns-that-have-more-than-10,000-null-values-in-them\" data-toc-modified-id=\"Remove-the-columns-that-have-more-than-10,000-null-values-in-them-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Remove the columns that have more than 10,000 null values in them</a></span></li><li><span><a href=\"#Create-a-new-dataframe-that-shows-only-the-row-where-displ-is-null.\" data-toc-modified-id=\"Create-a-new-dataframe-that-shows-only-the-row-where-displ-is-null.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Create a new dataframe that shows only the row where <code>displ</code> is null.</a></span></li><li><span><a href=\"#Fill-nan-values-with-the-most-appropriate-technique\" data-toc-modified-id=\"Fill-nan-values-with-the-most-appropriate-technique-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Fill nan values with the most appropriate technique</a></span></li><li><span><a href=\"#Bonus:\" data-toc-modified-id=\"Bonus:-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Bonus:</a></span></li></ul></li><li><span><a href=\"#Incorrect-Values\" data-toc-modified-id=\"Incorrect-Values-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Incorrect Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-similar-rows\" data-toc-modified-id=\"Check-similar-rows-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Check similar rows</a></span></li><li><span><a href=\"#Bonus:\" data-toc-modified-id=\"Bonus:-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Bonus:</a></span></li></ul></li><li><span><a href=\"#Low-Variance-Columns\" data-toc-modified-id=\"Low-Variance-Columns-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Low Variance Columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-the-the-drop-method-like-we-did-earlier-in-this-lesson-to-remove-the-non-informative-columns-from-our-data-frame.\" data-toc-modified-id=\"Use-the-the-drop-method-like-we-did-earlier-in-this-lesson-to-remove-the-non-informative-columns-from-our-data-frame.-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Use the the drop method like we did earlier in this lesson to remove the non informative columns from our data frame.</a></span></li></ul></li><li><span><a href=\"#Extreme-Values-and-Outliers\" data-toc-modified-id=\"Extreme-Values-and-Outliers-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extreme Values and Outliers</a></span></li><li><span><a href=\"#Data-Type-Correction\" data-toc-modified-id=\"Data-Type-Correction-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Data Type Correction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-the-data-type-of-each-column\" data-toc-modified-id=\"Check-the-data-type-of-each-column-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Check the data type of each column</a></span></li><li><span><a href=\"#Cleaning-years\" data-toc-modified-id=\"Cleaning-years-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Cleaning years</a></span></li></ul></li><li><span><a href=\"#Cleaning-Text-and-Removing-Special-Characters\" data-toc-modified-id=\"Cleaning-Text-and-Removing-Special-Characters-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Cleaning Text and Removing Special Characters</a></span></li><li><span><a href=\"#Finding-and-Removing-Duplicates\" data-toc-modified-id=\"Finding-and-Removing-Duplicates-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Finding and Removing Duplicates</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drop-duplicate-rows-that-are-completely-equal\" data-toc-modified-id=\"Drop-duplicate-rows-that-are-completely-equal-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Drop duplicate rows that are completely equal</a></span></li><li><span><a href=\"#Select-a-subset-of-columns,-remove-all-other-columns,-and-then-use-the-drop_duplicates-method-to-drop-any-duplicate-records-based-on-the-remaining-columns.\" data-toc-modified-id=\"Select-a-subset-of-columns,-remove-all-other-columns,-and-then-use-the-drop_duplicates-method-to-drop-any-duplicate-records-based-on-the-remaining-columns.-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Select a subset of columns, remove all other columns, and then use the drop_duplicates method to drop any duplicate records based on the remaining columns.</a></span></li></ul></li><li><span><a href=\"#Export-clean-dataset\" data-toc-modified-id=\"Export-clean-dataset-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Export clean dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "Lab Goals\n",
    "\n",
    "+ Examine data for potential issues.\n",
    "+ Identify and fill in missing values.\n",
    "+ Identify and correct incorrect values.\n",
    "+ Remove low variance columns.\n",
    "+ Identify potential outliers.\n",
    "+ Correct incorrect data types.\n",
    "+ Remove special characters and clean categorical variables.\n",
    "+ Identify and remove duplicate records.\n",
    "\n",
    "Introduction\n",
    "\n",
    "When working with data sets, you will find that they often require a bit of cleaning. Whether Pandas originally read the data types incorrectly, records are duplicated, the data contains special characters or missing value, or there are slightly different references to the same entity, every data analyst must know how to clean the data they are working with before analyzing it. In this lesson, you will learn about some of the most common problems that make data messy and methods for correcting those problems and cleaning your data.\n",
    "\n",
    "The data set we are going to be using for this lesson is a messy version of the vehicles data set we worked with in the previous lesson. Let's import this version of our data set so that we can then practice cleaning it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\1513472031.py:4: DtypeWarning: Columns (70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(str(actual_path) + '/vehicles_messy.csv')\n"
     ]
    }
   ],
   "source": [
    "#Load data from vehicles_messy.csv\n",
    "import pathlib\n",
    "actual_path = pathlib.Path().absolute()\n",
    "data = pd.read_csv(str(actual_path) + '/vehicles_messy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Data for Potential Issues\n",
    "\n",
    "One of the first things we want to do is examine the data and look for any **potential issues**. Some of the things we are interested in identifying in the data at this stage include:\n",
    "\n",
    "- Missing values\n",
    "- Special characters\n",
    "- Incorrect values\n",
    "- Extreme values or outliers\n",
    "- Duplicate records\n",
    "- Incorrect data types\n",
    "\n",
    "The presence of these may cause problems when it's time to analyze the data, so we want to make sure we address them beforehand. We can start by visually inspecting the data using the `.head` method, which will show us the first 5 rows of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   barrels08  barrelsA08  charge120  charge240  city08  city08U  cityA08  \\\n",
      "0  15.695714         0.0        0.0        0.0      19      0.0        0   \n",
      "1  29.964545         0.0        0.0        0.0       9      0.0        0   \n",
      "2  12.207778         0.0        0.0        0.0      23      0.0        0   \n",
      "3  29.964545         0.0        0.0        0.0      10      0.0        0   \n",
      "4  17.347895         0.0        0.0        0.0      17      0.0        0   \n",
      "\n",
      "   cityA08U  cityCD  cityE  ...  mfrCode  c240Dscr  charge240b  c240bDscr  \\\n",
      "0       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
      "1       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
      "2       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
      "3       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
      "4       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
      "\n",
      "                      createdOn                    modifiedOn  startStop  \\\n",
      "0  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
      "1  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
      "2  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
      "3  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
      "4  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
      "\n",
      "   phevCity  phevHwy  phevComb  \n",
      "0         0        0         0  \n",
      "1         0        0         0  \n",
      "2         0        0         0  \n",
      "3         0        0         0  \n",
      "4         0        0         0  \n",
      "\n",
      "[5 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how big actually is our dataframe??? Check it with `.shape` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37843, 83)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive a little more in the content of our data set. Is there any method that shows us the **column names**, its **data types** and number of **non-null values**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37843 entries, 0 to 37842\n",
      "Data columns (total 83 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   barrels08        37843 non-null  float64\n",
      " 1   barrelsA08       37843 non-null  float64\n",
      " 2   charge120        37843 non-null  float64\n",
      " 3   charge240        37843 non-null  float64\n",
      " 4   city08           37843 non-null  int64  \n",
      " 5   city08U          37843 non-null  float64\n",
      " 6   cityA08          37843 non-null  int64  \n",
      " 7   cityA08U         37843 non-null  float64\n",
      " 8   cityCD           37843 non-null  float64\n",
      " 9   cityE            37843 non-null  float64\n",
      " 10  cityUF           37843 non-null  float64\n",
      " 11  co2              37843 non-null  int64  \n",
      " 12  co2A             37843 non-null  int64  \n",
      " 13  co2TailpipeAGpm  37843 non-null  float64\n",
      " 14  co2TailpipeGpm   37843 non-null  float64\n",
      " 15  comb08           37843 non-null  int64  \n",
      " 16  comb08U          37843 non-null  float64\n",
      " 17  combA08          37843 non-null  int64  \n",
      " 18  combA08U         37843 non-null  float64\n",
      " 19  combE            37843 non-null  float64\n",
      " 20  combinedCD       37843 non-null  float64\n",
      " 21  combinedUF       37843 non-null  float64\n",
      " 22  cylinders        37720 non-null  float64\n",
      " 23  displ            37723 non-null  float64\n",
      " 24  drive            36654 non-null  object \n",
      " 25  engId            37843 non-null  int64  \n",
      " 26  eng_dscr         22440 non-null  object \n",
      " 27  feScore          37843 non-null  int64  \n",
      " 28  fuelCost08       37843 non-null  int64  \n",
      " 29  fuelCostA08      37843 non-null  int64  \n",
      " 30  fuelType         37843 non-null  object \n",
      " 31  fuelType1        37843 non-null  object \n",
      " 32  ghgScore         37843 non-null  int64  \n",
      " 33  ghgScoreA        37843 non-null  int64  \n",
      " 34  highway08        37843 non-null  int64  \n",
      " 35  highway08U       37843 non-null  float64\n",
      " 36  highwayA08       37843 non-null  int64  \n",
      " 37  highwayA08U      37843 non-null  float64\n",
      " 38  highwayCD        37843 non-null  float64\n",
      " 39  highwayE         37843 non-null  float64\n",
      " 40  highwayUF        37843 non-null  float64\n",
      " 41  hlv              37843 non-null  int64  \n",
      " 42  hpv              37843 non-null  int64  \n",
      " 43  id               37843 non-null  int64  \n",
      " 44  lv2              37843 non-null  int64  \n",
      " 45  lv4              37843 non-null  int64  \n",
      " 46  make             37843 non-null  object \n",
      " 47  model            37843 non-null  object \n",
      " 48  mpgData          37843 non-null  object \n",
      " 49  phevBlended      37843 non-null  bool   \n",
      " 50  pv2              37843 non-null  int64  \n",
      " 51  pv4              37843 non-null  int64  \n",
      " 52  range            37843 non-null  int64  \n",
      " 53  rangeCity        37843 non-null  float64\n",
      " 54  rangeCityA       37843 non-null  float64\n",
      " 55  rangeHwy         37843 non-null  float64\n",
      " 56  rangeHwyA        37843 non-null  float64\n",
      " 57  trany            37832 non-null  object \n",
      " 58  UCity            37843 non-null  float64\n",
      " 59  UCityA           37843 non-null  float64\n",
      " 60  UHighway         37843 non-null  float64\n",
      " 61  UHighwayA        37843 non-null  float64\n",
      " 62  VClass           37843 non-null  object \n",
      " 63  year             37843 non-null  int64  \n",
      " 64  youSaveSpend     37843 non-null  int64  \n",
      " 65  guzzler          2281 non-null   object \n",
      " 66  trans_dscr       15047 non-null  object \n",
      " 67  tCharger         5186 non-null   object \n",
      " 68  sCharger         666 non-null    object \n",
      " 69  atvType          3072 non-null   object \n",
      " 70  fuelType2        1408 non-null   object \n",
      " 71  rangeA           1403 non-null   object \n",
      " 72  evMotor          562 non-null    object \n",
      " 73  mfrCode          7025 non-null   object \n",
      " 74  c240Dscr         37 non-null     object \n",
      " 75  charge240b       37843 non-null  float64\n",
      " 76  c240bDscr        36 non-null     object \n",
      " 77  createdOn        37843 non-null  object \n",
      " 78  modifiedOn       37843 non-null  object \n",
      " 79  startStop        6138 non-null   object \n",
      " 80  phevCity         37843 non-null  int64  \n",
      " 81  phevHwy          37843 non-null  int64  \n",
      " 82  phevComb         37843 non-null  int64  \n",
      "dtypes: bool(1), float64(32), int64(27), object(23)\n",
      "memory usage: 23.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "From this initial view, we can see that our data set contains some columns that have missing values in them and others that seem to have a lot of zero values. \n",
    "\n",
    "Let's see how prevalent missing values are in our data. We can use the Pandas `.isnull()` method to check whether the value in each field is missing (*null*) and return either True or False for each field. \n",
    "\n",
    "We can use the `.sum()` method to total up the number of True values by column, and then we can add a condition using square brackets that will filter the data and show us only columns where the number of null values were greater than zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the number of null values only of the columns that actually have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barrels08         0\n",
      "barrelsA08        0\n",
      "charge120         0\n",
      "charge240         0\n",
      "city08            0\n",
      "              ...  \n",
      "modifiedOn        0\n",
      "startStop     31705\n",
      "phevCity          0\n",
      "phevHwy           0\n",
      "phevComb          0\n",
      "Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some columns have relatively few null values while others have tens of thousands of nulls. For fields that have a lot of null values, you will often have to make a judgement call. If you don't think the information is going to be very useful to your analysis, then you would remove those columns from your data frame. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the columns that have more than 10,000 null values in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can do that using the drop method. For our purposes, let's remove the columns that have more than 10,000 null values in them. We will add these column names to a list, and then we will pass those columns to the drop method and indicate that we want columns (not rows) dropped by setting the axis parameter to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37843, 72)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "data = data.dropna(axis=1, thresh=10000)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with just a handful of remaining columns that have null values. Of the columns that remain, it looks like the cylinders column and the displ column have a similar number of nulls. Perhaps they are missing for similar reasons. We can investigate this by subsetting the data set and looking at just the records where displ is null and just the columns we think will be informative in allowing us to determine a reason. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new dataframe that shows only the row where `displ` is null. \n",
    "Keep only the columns you think are useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       barrels08  barrelsA08  charge120  charge240  city08   city08U  cityA08  \\\n",
      "7138       0.240         0.0        0.0        0.0      81    0.0000        0   \n",
      "7139       0.282         0.0        0.0        0.0      81    0.0000        0   \n",
      "8143       0.282         0.0        0.0        0.0      81    0.0000        0   \n",
      "8144       0.312         0.0        0.0        0.0      74    0.0000        0   \n",
      "8146       0.522         0.0        0.0        0.0      45    0.0000        0   \n",
      "...          ...         ...        ...        ...     ...       ...      ...   \n",
      "30969      0.192         0.0        0.0        4.0     120  119.6000        0   \n",
      "30972      0.204         0.0        0.0       10.0      98   97.5636        0   \n",
      "30973      0.192         0.0        0.0       12.0     101  101.4750        0   \n",
      "30974      0.210         0.0        0.0       12.0      92   92.4713        0   \n",
      "30975      0.216         0.0        0.0       12.0      91   91.2362        0   \n",
      "\n",
      "       cityA08U  cityCD    cityE  ...                              VClass  \\\n",
      "7138        0.0     0.0  41.0000  ...              Midsize Station Wagons   \n",
      "7139        0.0     0.0  41.0000  ...         Sport Utility Vehicle - 2WD   \n",
      "8143        0.0     0.0  41.0000  ...         Sport Utility Vehicle - 2WD   \n",
      "8144        0.0     0.0  46.0000  ...                         Two Seaters   \n",
      "8146        0.0     0.0  75.0000  ...         Sport Utility Vehicle - 2WD   \n",
      "...         ...     ...      ...  ...                                 ...   \n",
      "30969       0.0     0.0  28.1744  ...                Small Station Wagons   \n",
      "30972       0.0     0.0  35.0000  ...                          Large Cars   \n",
      "30973       0.0     0.0  33.0000  ...                          Large Cars   \n",
      "30974       0.0     0.0  36.0000  ...                          Large Cars   \n",
      "30975       0.0     0.0  37.0000  ...  Standard Sport Utility Vehicle 4WD   \n",
      "\n",
      "       year  youSaveSpend  trans_dscr  charge240b  \\\n",
      "7138   2000          2750         NaN        0.00   \n",
      "7139   2000          2250         NaN        0.00   \n",
      "8143   2001          2250         NaN        0.00   \n",
      "8144   2001          1750         NaN        0.00   \n",
      "8146   2001         -1750         NaN        0.00   \n",
      "...     ...           ...         ...         ...   \n",
      "30969  2017          3750         NaN        0.00   \n",
      "30972  2016          3500         NaN        3.75   \n",
      "30973  2016          3750         NaN        3.75   \n",
      "30974  2016          3250         NaN        4.75   \n",
      "30975  2016          3250         NaN        4.75   \n",
      "\n",
      "                          createdOn                    modifiedOn  phevCity  \\\n",
      "7138   Tue Jan 01 00:00:00 EST 2013  Thu Jul 07 00:00:00 EDT 2016         0   \n",
      "7139   Tue Jan 01 00:00:00 EST 2013  Thu Jul 07 00:00:00 EDT 2016         0   \n",
      "8143   Tue Jan 01 00:00:00 EST 2013  Thu Jul 07 00:00:00 EDT 2016         0   \n",
      "8144   Tue Jan 01 00:00:00 EST 2013  Thu Jul 07 00:00:00 EDT 2016         0   \n",
      "8146   Tue Jan 01 00:00:00 EST 2013  Thu Jul 07 00:00:00 EDT 2016         0   \n",
      "...                             ...                           ...       ...   \n",
      "30969  Tue Sep 13 00:00:00 EDT 2016  Tue Sep 13 00:00:00 EDT 2016         0   \n",
      "30972  Tue Sep 13 00:00:00 EDT 2016  Tue Sep 13 00:00:00 EDT 2016         0   \n",
      "30973  Tue Sep 13 00:00:00 EDT 2016  Tue Sep 13 00:00:00 EDT 2016         0   \n",
      "30974  Tue Sep 13 00:00:00 EDT 2016  Tue Sep 13 00:00:00 EDT 2016         0   \n",
      "30975  Tue Sep 13 00:00:00 EDT 2016  Tue Sep 13 00:00:00 EDT 2016         0   \n",
      "\n",
      "       phevHwy  phevComb  \n",
      "7138         0         0  \n",
      "7139         0         0  \n",
      "8143         0         0  \n",
      "8144         0         0  \n",
      "8146         0         0  \n",
      "...        ...       ...  \n",
      "30969        0         0  \n",
      "30972        0         0  \n",
      "30973        0         0  \n",
      "30974        0         0  \n",
      "30975        0         0  \n",
      "\n",
      "[120 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "data_displ_null = data[data['displ'].isnull()]\n",
    "print(data_displ_null)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill nan values with the most appropriate technique \n",
    "*HINT: Electric cars do not have cylinders and can therefore not have any displacement*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "data['displ'] = data['displ'].fillna(data['displ'].mean())\n",
    "print(data['displ'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: \n",
    "Now that we have filled in those null values, there are only two columns in the data set that still have null values: trany and drive. Use what you have learned in this section to investigate and potentially fill in the remaining null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       barrels08  barrelsA08  charge120  charge240  city08  city08U  cityA08  \\\n",
      "7138    0.240000         0.0        0.0        0.0      81      0.0        0   \n",
      "7139    0.282000         0.0        0.0        0.0      81      0.0        0   \n",
      "8143    0.282000         0.0        0.0        0.0      81      0.0        0   \n",
      "8144    0.312000         0.0        0.0        0.0      74      0.0        0   \n",
      "8146    0.522000         0.0        0.0        0.0      45      0.0        0   \n",
      "8147    0.270000         0.0        0.0        0.0      84      0.0        0   \n",
      "9212    0.258000         0.0        0.0        0.0      87      0.0        0   \n",
      "9213    0.522000         0.0        0.0        0.0      45      0.0        0   \n",
      "10329   0.258000         0.0        0.0        0.0      87      0.0        0   \n",
      "19097  29.964545         0.0        0.0        0.0      11      0.0        0   \n",
      "19128  23.543571         0.0        0.0        0.0      13      0.0        0   \n",
      "\n",
      "       cityA08U  cityCD  cityE  ...                       VClass  year  \\\n",
      "7138        0.0     0.0   41.0  ...       Midsize Station Wagons  2000   \n",
      "7139        0.0     0.0   41.0  ...  Sport Utility Vehicle - 2WD  2000   \n",
      "8143        0.0     0.0   41.0  ...  Sport Utility Vehicle - 2WD  2001   \n",
      "8144        0.0     0.0   46.0  ...                  Two Seaters  2001   \n",
      "8146        0.0     0.0   75.0  ...  Sport Utility Vehicle - 2WD  2001   \n",
      "8147        0.0     0.0   40.0  ...                  Two Seaters  2001   \n",
      "9212        0.0     0.0   39.0  ...  Sport Utility Vehicle - 2WD  2002   \n",
      "9213        0.0     0.0   75.0  ...  Sport Utility Vehicle - 2WD  2002   \n",
      "10329       0.0     0.0   39.0  ...  Sport Utility Vehicle - 2WD  2003   \n",
      "19097       0.0     0.0    0.0  ...   Standard Pickup Trucks 2WD  1984   \n",
      "19128       0.0     0.0    0.0  ...   Standard Pickup Trucks 2WD  1984   \n",
      "\n",
      "       youSaveSpend  trans_dscr  charge240b                     createdOn  \\\n",
      "7138           2750         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "7139           2250         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "8143           2250         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "8144           1750         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "8146          -1750         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "8147           2250         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "9212           2500         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "9213          -1750         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "10329          2500         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "19097         -8500         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "19128         -5250         NaN         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
      "\n",
      "                         modifiedOn  phevCity  phevHwy  phevComb  \n",
      "7138   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "7139   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "8143   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "8144   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "8146   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "8147   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "9212   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "9213   Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "10329  Thu Jul 07 00:00:00 EDT 2016         0        0         0  \n",
      "19097  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
      "19128  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
      "\n",
      "[11 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "data_trany_null = data[data['trany'].isnull()]\n",
    "print(data_trany_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorrect Values\n",
    "\n",
    "In addition to null values, we also want to try to identify any values that seem incorrect. For example, in the previous section, we learned that a vehicle without cylinders should not have displacement and vice versa. Let's check to see if there are any cases that violate these rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data[(data['cylinders'] == 0) & (data['displ'] != 0)].shape[0])\n",
    "print(data[(data['cylinders'] != 0) & (data['displ'] == 0)].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any row that seems to have strange values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your explanation here\n",
    "# Yes, there are rows where cylinders is not 0 and displacement is 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have identified a vehicle with a regular gasoline engine that reportedly does not have any cylinders but does have a value for displacement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we would correct this would be to either perform some domain research or ask a domain expert to find out how many actual cylinders this vehicle had. Alternatively, you can also try to look at similar vehicles in the data set and determine the most likely value for this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check similar rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that using one of the aforementioned methods, we found out that this vehicle actually has a 4 cylinder engine. Update that specific value in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [barrels08, barrelsA08, charge120, charge240, city08, city08U, cityA08, cityA08U, cityCD, cityE, cityUF, co2, co2A, co2TailpipeAGpm, co2TailpipeGpm, comb08, comb08U, combA08, combA08U, combE, combinedCD, combinedUF, cylinders, displ, drive, engId, eng_dscr, feScore, fuelCost08, fuelCostA08, fuelType, fuelType1, ghgScore, ghgScoreA, highway08, highway08U, highwayA08, highwayA08U, highwayCD, highwayE, highwayUF, hlv, hpv, id, lv2, lv4, make, model, mpgData, phevBlended, pv2, pv4, range, rangeCity, rangeCityA, rangeHwy, rangeHwyA, trany, UCity, UCityA, UHighway, UHighwayA, VClass, year, youSaveSpend, trans_dscr, charge240b, createdOn, modifiedOn, phevCity, phevHwy, phevComb]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data[(data['cylinders'] == 0) & (data['displ'] != 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: \n",
    " Try to find other values that might be incorrect in the data set based on what you know about automobiles and correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "data.loc[21506, 'cylinders'] = 4\n",
    "print(data.loc[21506, 'cylinders'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Variance Columns\n",
    "\n",
    "When analyzing data, we want the fields we are working with to be informative, and we will want to strip away any columns that don't have a lot of value to us. One easy way to do this is to identify columns that have low variance, where the majority of the values in the column are the same. Since there is not a lot of variability in these columns, they have the potential to not be as informative as columns that have a variety of different values in them.\n",
    "\n",
    "Let's try to identify columns where at least 90% of the values are the same so that we can remove them from our data set. To do this, we are going to create an empty list called low_variance that will eventually contain the names of columns that fit our criteria.\n",
    "\n",
    "We will then write a for loop that will take the minimum and the 90th percentile value for all the numeric columns in our data set (identified via the _get_numeric_data method). If the 90th percentile and the minimum are equal to each other, that means that at least 90% of the values in that column are the same and we will append that column name to our low_variance list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barrels08', 'barrelsA08', 'charge120', 'charge240', 'cityA08', 'cityA08U', 'cityCD', 'cityE', 'cityUF', 'combA08', 'combA08U', 'combE', 'combinedCD', 'combinedUF', 'cylinders', 'displ', 'feScore', 'ghgScore', 'ghgScoreA', 'highwayA08', 'highwayA08U', 'highwayCD', 'highwayE', 'highwayUF', 'hlv', 'lv2', 'rangeCityA', 'rangeHwyA', 'UCityA', 'UHighwayA', 'charge240b', 'phevCity', 'phevHwy', 'phevComb']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "low_variance = []\n",
    "for c in data.select_dtypes(include=np.number): \n",
    "    \n",
    "    if 0 <= data[c].std() <=6.5: \n",
    "        low_variance.append(c)\n",
    "print(low_variance)\n",
    "print(len(low_variance))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned 34 columns that we could potentially eliminate due to not having high enough variability to be informative. Of course, before we do this, we should check the values that do exist in these fields to confirm that they are not very informative. Once they have been checked, we can use the the drop method like we did earlier in this lesson to remove those columns from our data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the the drop method like we did earlier in this lesson to remove the non informative columns from our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "data.drop(low_variance, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Values and Outliers\n",
    "\n",
    "Now that we have removed low variance columns, we should look for outliers, or extreme values, in the columns that remain. These outliers can influence our aggregations when we are analyzing data later, so we want to make sure we address them during our data cleaning stage.\n",
    "\n",
    "A common method for identifying outliers is one that leverages the interquartile range (IQR). Once the IQR is calculated, it is multiplied by a constant (typically 1.5) and lower and upper bounds are established at:\n",
    "\n",
    "    25th Percentile - (IQR x 1.5)\n",
    "    75th Percentile + (IQR x 1.5)\n",
    "\n",
    "Any values outside this range are potential outliers and should be investigated.\n",
    "\n",
    "Let's look at how we would do this for our data set using Python. We will use the Pandas describe function to easily calculate the 25th and 75th percentiles for every column and transpose the results so that we can easily reference the values in calculating the interquartile ranges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>IQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>city08</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>17.941389</td>\n",
       "      <td>6.660360</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city08U</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>4.042737</td>\n",
       "      <td>9.645820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>138.304000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>61.503713</td>\n",
       "      <td>153.387715</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2A</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>5.349919</td>\n",
       "      <td>55.539497</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2TailpipeAGpm</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>17.771433</td>\n",
       "      <td>94.129283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2TailpipeGpm</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>473.179736</td>\n",
       "      <td>122.188847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>467.736842</td>\n",
       "      <td>555.4375</td>\n",
       "      <td>1269.571429</td>\n",
       "      <td>167.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comb08</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>20.195809</td>\n",
       "      <td>6.623444</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comb08U</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>4.549751</td>\n",
       "      <td>10.389994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>124.360100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engId</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>8860.308961</td>\n",
       "      <td>17829.683477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>4505.0000</td>\n",
       "      <td>69102.000000</td>\n",
       "      <td>4505.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelCost08</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>1882.060090</td>\n",
       "      <td>510.280408</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>2200.0000</td>\n",
       "      <td>5800.000000</td>\n",
       "      <td>700.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelCostA08</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>79.070105</td>\n",
       "      <td>417.668580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3800.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway08</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>24.104881</td>\n",
       "      <td>6.963192</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway08U</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>5.438467</td>\n",
       "      <td>11.936327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>111.370000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>10.424332</td>\n",
       "      <td>28.148770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>19019.286235</td>\n",
       "      <td>11034.784855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9461.5</td>\n",
       "      <td>18923.000000</td>\n",
       "      <td>28570.5000</td>\n",
       "      <td>38173.000000</td>\n",
       "      <td>19109.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lv4</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>6.165658</td>\n",
       "      <td>9.743297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pv2</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>13.696113</td>\n",
       "      <td>31.269930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pv4</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>33.769125</td>\n",
       "      <td>45.914462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.0000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>91.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>range</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>0.392675</td>\n",
       "      <td>8.251191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rangeCity</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>0.352618</td>\n",
       "      <td>8.049082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>305.900000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rangeHwy</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>0.343399</td>\n",
       "      <td>8.171939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>346.900000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCity</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>22.587229</td>\n",
       "      <td>9.350163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>25.1393</td>\n",
       "      <td>197.577100</td>\n",
       "      <td>7.1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UHighway</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>33.619221</td>\n",
       "      <td>10.048326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>38.1096</td>\n",
       "      <td>159.100000</td>\n",
       "      <td>11.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>2000.064398</td>\n",
       "      <td>10.390588</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2009.0000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>19.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youSaveSpend</th>\n",
       "      <td>37843.0</td>\n",
       "      <td>-2658.999022</td>\n",
       "      <td>2553.098329</td>\n",
       "      <td>-22250.0</td>\n",
       "      <td>-4250.0</td>\n",
       "      <td>-2500.000000</td>\n",
       "      <td>-750.0000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>3500.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std      min     25%  \\\n",
       "city08           37843.0     17.941389      6.660360      6.0    15.0   \n",
       "city08U          37843.0      4.042737      9.645820      0.0     0.0   \n",
       "co2              37843.0     61.503713    153.387715     -1.0    -1.0   \n",
       "co2A             37843.0      5.349919     55.539497     -1.0    -1.0   \n",
       "co2TailpipeAGpm  37843.0     17.771433     94.129283      0.0     0.0   \n",
       "co2TailpipeGpm   37843.0    473.179736    122.188847      0.0   388.0   \n",
       "comb08           37843.0     20.195809      6.623444      7.0    17.0   \n",
       "comb08U          37843.0      4.549751     10.389994      0.0     0.0   \n",
       "engId            37843.0   8860.308961  17829.683477      0.0     0.0   \n",
       "fuelCost08       37843.0   1882.060090    510.280408    550.0  1500.0   \n",
       "fuelCostA08      37843.0     79.070105    417.668580      0.0     0.0   \n",
       "highway08        37843.0     24.104881      6.963192      9.0    20.0   \n",
       "highway08U       37843.0      5.438467     11.936327      0.0     0.0   \n",
       "hpv              37843.0     10.424332     28.148770      0.0     0.0   \n",
       "id               37843.0  19019.286235  11034.784855      1.0  9461.5   \n",
       "lv4              37843.0      6.165658      9.743297      0.0     0.0   \n",
       "pv2              37843.0     13.696113     31.269930      0.0     0.0   \n",
       "pv4              37843.0     33.769125     45.914462      0.0     0.0   \n",
       "range            37843.0      0.392675      8.251191      0.0     0.0   \n",
       "rangeCity        37843.0      0.352618      8.049082      0.0     0.0   \n",
       "rangeHwy         37843.0      0.343399      8.171939      0.0     0.0   \n",
       "UCity            37843.0     22.587229      9.350163      0.0    18.0   \n",
       "UHighway         37843.0     33.619221     10.048326      0.0    27.1   \n",
       "year             37843.0   2000.064398     10.390588   1984.0  1990.0   \n",
       "youSaveSpend     37843.0  -2658.999022   2553.098329 -22250.0 -4250.0   \n",
       "\n",
       "                          50%         75%           max         IQR  \n",
       "city08              17.000000     20.0000    138.000000      5.0000  \n",
       "city08U              0.000000      0.0000    138.304000      0.0000  \n",
       "co2                 -1.000000     -1.0000    847.000000      0.0000  \n",
       "co2A                -1.000000     -1.0000    719.000000      0.0000  \n",
       "co2TailpipeAGpm      0.000000      0.0000    719.000000      0.0000  \n",
       "co2TailpipeGpm     467.736842    555.4375   1269.571429    167.4375  \n",
       "comb08              19.000000     23.0000    124.000000      6.0000  \n",
       "comb08U              0.000000      0.0000    124.360100      0.0000  \n",
       "engId              211.000000   4505.0000  69102.000000   4505.0000  \n",
       "fuelCost08        1850.000000   2200.0000   5800.000000    700.0000  \n",
       "fuelCostA08          0.000000      0.0000   3800.000000      0.0000  \n",
       "highway08           24.000000     27.0000    111.000000      7.0000  \n",
       "highway08U           0.000000      0.0000    111.370000      0.0000  \n",
       "hpv                  0.000000      0.0000    195.000000      0.0000  \n",
       "id               18923.000000  28570.5000  38173.000000  19109.0000  \n",
       "lv4                  0.000000     13.0000     55.000000     13.0000  \n",
       "pv2                  0.000000      0.0000    194.000000      0.0000  \n",
       "pv4                  0.000000     91.0000    192.000000     91.0000  \n",
       "range                0.000000      0.0000    315.000000      0.0000  \n",
       "rangeCity            0.000000      0.0000    305.900000      0.0000  \n",
       "rangeHwy             0.000000      0.0000    346.900000      0.0000  \n",
       "UCity               21.000000     25.1393    197.577100      7.1393  \n",
       "UHighway            33.000000     38.1096    159.100000     11.0096  \n",
       "year              2001.000000   2009.0000   2017.000000     19.0000  \n",
       "youSaveSpend     -2500.000000   -750.0000   4000.000000   3500.0000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this code\n",
    "stats = data.describe().transpose()\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create an empty data frame called outliers with the same columns as our data set. Finally, we will loop through each column in the data calculating the lower and upper bounds, retrieving records where the value for that column falls outside the bounds we established, and appending those results to our outlier data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outliers = outliers.append(results)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\3046509943.py:12: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  outliers = outliers.append(results)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city08</th>\n",
       "      <th>city08U</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2A</th>\n",
       "      <th>co2TailpipeAGpm</th>\n",
       "      <th>co2TailpipeGpm</th>\n",
       "      <th>comb08</th>\n",
       "      <th>comb08U</th>\n",
       "      <th>drive</th>\n",
       "      <th>engId</th>\n",
       "      <th>...</th>\n",
       "      <th>trany</th>\n",
       "      <th>UCity</th>\n",
       "      <th>UHighway</th>\n",
       "      <th>VClass</th>\n",
       "      <th>year</th>\n",
       "      <th>youSaveSpend</th>\n",
       "      <th>trans_dscr</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.382353</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>49010</td>\n",
       "      <td>...</td>\n",
       "      <td>Manual 4-spd</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>1985</td>\n",
       "      <td>1750</td>\n",
       "      <td>SIL</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>city08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.303030</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>26007</td>\n",
       "      <td>...</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>1994</td>\n",
       "      <td>1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>city08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.387097</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>24680</td>\n",
       "      <td>...</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>38.8889</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Special Purpose Vehicles</td>\n",
       "      <td>1985</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>city08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.303030</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>54003</td>\n",
       "      <td>...</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>1994</td>\n",
       "      <td>1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>city08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.756098</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>54003</td>\n",
       "      <td>...</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>1994</td>\n",
       "      <td>2750</td>\n",
       "      <td>SIL</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>city08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city08  city08U co2 co2A  co2TailpipeAGpm  co2TailpipeGpm comb08  comb08U  \\\n",
       "446     31      0.0  -1   -1              0.0      261.382353     34      0.0   \n",
       "705     30      0.0  -1   -1              0.0      269.303030     33      0.0   \n",
       "724     30      0.0  -1   -1              0.0      328.387097     31      0.0   \n",
       "775     31      0.0  -1   -1              0.0      269.303030     33      0.0   \n",
       "776     38      0.0  -1   -1              0.0      216.756098     41      0.0   \n",
       "\n",
       "                 drive  engId  ...            trany    UCity UHighway  \\\n",
       "446  Front-Wheel Drive  49010  ...     Manual 4-spd  41.0000     53.0   \n",
       "705  Front-Wheel Drive  26007  ...     Manual 5-spd  39.0000     53.0   \n",
       "724  Front-Wheel Drive  24680  ...     Manual 5-spd  38.8889     45.0   \n",
       "775  Front-Wheel Drive  54003  ...  Automatic 3-spd  40.0000     51.0   \n",
       "776  Front-Wheel Drive  54003  ...     Manual 5-spd  51.0000     64.0   \n",
       "\n",
       "                       VClass  year youSaveSpend  trans_dscr  \\\n",
       "446           Subcompact Cars  1985         1750         SIL   \n",
       "705               Two Seaters  1994         1750         NaN   \n",
       "724  Special Purpose Vehicles  1985         1000         NaN   \n",
       "775           Subcompact Cars  1994         1750         NaN   \n",
       "776           Subcompact Cars  1994         2750         SIL   \n",
       "\n",
       "                        createdOn                    modifiedOn Outlier  \n",
       "446  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013  city08  \n",
       "705  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013  city08  \n",
       "724  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013  city08  \n",
       "775  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013  city08  \n",
       "776  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013  city08  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this code\n",
    "outliers = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = data[(data[col] < lower) | \n",
    "                   (data[col] > upper)].copy()\n",
    "    results['Outlier'] = col\n",
    "    outliers = outliers.append(results)\n",
    "    \n",
    "\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our outliers data frame should now be populated with records that you can investigate further and determine whether they should be kept in the data or dropped. The Outlier column we added before appending the results for the column to the outliers data frame will let you know what column in each record contained the outlier. If you find that this method is returning too many results, you can be more stringent with your cutoff criteria (e.g. increasing the constant by which you multiply the IQR to 3 instead of 1.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Type Correction\n",
    "\n",
    "One common problem that is often overlooked is incorrect data types. This typically occurs when there is a numeric variable that should actually be represented as a categorical variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city08               int64\n",
      "city08U            float64\n",
      "co2                  int64\n",
      "co2A                 int64\n",
      "co2TailpipeAGpm    float64\n",
      "co2TailpipeGpm     float64\n",
      "comb08               int64\n",
      "comb08U            float64\n",
      "drive               object\n",
      "engId                int64\n",
      "eng_dscr            object\n",
      "fuelCost08           int64\n",
      "fuelCostA08          int64\n",
      "fuelType            object\n",
      "fuelType1           object\n",
      "highway08            int64\n",
      "highway08U         float64\n",
      "hpv                  int64\n",
      "id                   int64\n",
      "lv4                  int64\n",
      "make                object\n",
      "model               object\n",
      "mpgData             object\n",
      "phevBlended           bool\n",
      "pv2                  int64\n",
      "pv4                  int64\n",
      "range                int64\n",
      "rangeCity          float64\n",
      "rangeHwy           float64\n",
      "trany               object\n",
      "UCity              float64\n",
      "UHighway           float64\n",
      "VClass              object\n",
      "year                 int64\n",
      "youSaveSpend         int64\n",
      "trans_dscr          object\n",
      "createdOn           object\n",
      "modifiedOn          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##your code\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning years\n",
    "Do you think column year is a continuous variable? Would you change it onto another dtype?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "data['year'] = data['year'].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply this technique to any column whose data type you would like to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "data['year'] = data['year'].astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Text and Removing Special Characters\n",
    "\n",
    "The presence of special characters in our fields has the potential to make analyzing our data challenging. Imagine not being able to perform calculations on a numeric field because it was currently represented as an object data type due to the fact that it had a dollar sign ($) in it. \n",
    "\n",
    "Similarly, imagine having a categorical field where you could not group records that belong in the same group together because in one field you are grouping by, terms that refer to the same thing are sometimes hyphenated. In cases like this, it is necessary to remove special characters so that we can properly analyze the data.\n",
    "\n",
    "In our vehicles data set, the trany field has several special characters (parentheses, hyphens, etc.). Check the unique values and clean the column.\n",
    "\n",
    "hint: check the `replace` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Manual 5-spd' 'Automatic 3-spd' 'Automatic 4-spd' 'Automatic 5-spd'\n",
      " 'Manual 4-spd' 'Manual 3-spd' 'Manual 6-spd' 'Automatic (S5)'\n",
      " 'Automatic (variable gear ratios)' 'Automatic 6-spd' 'Automatic (S6)'\n",
      " 'Automatic (S4)' 'Automatic 7-spd' 'Automatic (S7)' 'Automatic (S8)'\n",
      " 'Automatic (AM5)' 'Auto(AM6)' 'Auto(AV-S7)' 'Automatic (A6)'\n",
      " 'Automatic (AV-S6)' 'Auto(AM7)' 'Manual 4-spd Doubled' 'Manual 5 spd'\n",
      " 'Automatic (AM6)' 'Manual 7-spd' 'Auto(L4)' 'Auto(L3)' 'Automatic (AV)'\n",
      " 'Auto (AV-S6)' 'Auto(AM5)' 'Auto(AV-S6)' 'Auto (AV-S8)' 'Automatic 8-spd'\n",
      " 'Auto(AV-S8)' 'Automatic (A1)' 'Auto (AV)' 'Auto(AM-S6)' 'Auto(AM-S7)'\n",
      " 'Automatic 6spd' 'Automatic 9-spd' 'Automatic (S9)' 'Auto(AM-S8)'\n",
      " 'Auto(A1)' 'Auto(AM8)' 'Manual(M7)' 'Auto(AM-S9)']\n",
      "0           Manual 5-spd\n",
      "1           Manual 5-spd\n",
      "2           Manual 5-spd\n",
      "3        Automatic 3-spd\n",
      "4           Manual 5-spd\n",
      "              ...       \n",
      "37838    Automatic 4-spd\n",
      "37839       Manual 5-spd\n",
      "37840    Automatic 4-spd\n",
      "37841       Manual 5-spd\n",
      "37842    Automatic 4-spd\n",
      "Name: trany, Length: 37843, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\1867053276.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  print(data.trany.str.replace(r'[(,)]', ''))\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.trany.unique())\n",
    "print(data.trany.str.replace(r'[(,)]', ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have no special characters, consistent naming, and proper spacing. We started out with 47 unique values in this column, and using this technique, we were able to reduce the number of unique values to 39.\n",
    "\n",
    "\n",
    "\n",
    "# Finding and Removing Duplicates\n",
    "\n",
    "The final topic we are going to cover in this lab is how to identify and remove duplicate rows (or rows that refer to the same entity) in our data. When trying to identify duplicates, we will use the columns (or attributes) of the data to help us determine what entities are similar enough to be considered the same entity. We want to start with all the columns we currently have available to us and work our way toward a lesser number of attributes in an intuitive fashion. In this process, the act of dropping duplicated records is easy, but identifying the correct attributes for comparison and which records to drop is sometimes quite challenging.\n",
    "\n",
    "The first thing we will do is attempt to drop any duplicate records, considering all the columns we currently have in the data set. \n",
    "\n",
    "Pandas provides us with the ability to do that via the `drop_duplicates method`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicate rows that are completely equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37843, 38) (37843, 38)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "print(data.drop_duplicates().shape, data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that there were no records that matched exactly across all columns. However, if we reduce the number of columns in our data that we are interested in, we can try again and have a higher likelihood of finding duplicate records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of columns, remove all other columns, and then use the drop_duplicates method to drop any duplicate records based on the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36941, 7)\n",
      "Number of duplicate records dropped:  902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_17428\\1012976525.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "\n",
    "#print('Number of duplicate records dropped: ', str(before - after))\n",
    "\n",
    "subset = data[['make', 'model', 'year', 'drive', 'trany', 'UHighway', 'UCity']]\n",
    "subset.drop_duplicates(inplace=True)\n",
    "print(subset.shape)\n",
    "before= data.shape[0]\n",
    "after= subset.shape[0]\n",
    "\n",
    "print('Number of duplicate records dropped: ', str(before - after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the reduced number of columns, we were able to identify and drop 885 duplicate records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export clean dataset\n",
    "Export your bright new clean dataset into a csv file and store it in data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "data.to_csv('vehicles_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3e24519b0ba229a6f9a71f39c1cb5a8bdc9138e2d11e58c1de9e81a631b04fde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
